<!DOCTYPE html>
<html lang="en">
<head>
    <meta name="keywords" content="101, 1st, dsc, knowlet, notes, semester, statistics, unit">

    <meta name="description" content="Comprehensive notes for Statistics DSC 101 Unit 4 | 1st Semester Notes - Knowlet. Includes key concepts, definitions, and summaries for college students.">

    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Statistics DSC 101 Unit 4 | 1st Semester Notes - Knowlet</title>
    <link rel="stylesheet" href="../../../../assets/styles/units.css">
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            background-color: #f4f4f9;
            color: #333;
            margin: 0;
            padding: 20px;
        }
        .container {
            max-width: 900px;
            margin: auto;
            background: #fff;
            padding: 20px 30px;
            border-radius: 8px;
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.05);
        }
        h1 {
            color: #2c3e50;
            border-bottom: 3px solid #8e44ad;
            padding-bottom: 10px;
            text-align: center;
        }
        h2 {
            color: #8e44ad;
            border-bottom: 2px solid #E8DAEF;
            padding-bottom: 8px;
            margin-top: 30px;
        }
        h3 {
            color: #7d3c98;
            margin-top: 25px;
        }
        p {
            margin-bottom: 15px;
        }
        ul, ol {
            margin-left: 20px;
            margin-bottom: 15px;
        }
        li {
            margin-bottom: 8px;
        }
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
        }
        th, td {
            border: 1px solid #ddd;
            padding: 12px;
            text-align: left;
        }
        th {
            background-color: #8e44ad;
            color: white;
        }
        tr:nth-child(even) {
            background-color: #f9f9f9;
        }
        tr:hover {
            background-color: #f1f1f1;
        }
        blockquote {
            background: #E8DAEF;
            border-left: 5px solid #8e44ad;
            margin: 20px 0;
            padding: 15px 20px;
            font-style: italic;
            color: #555;
        }
        .exam-tip, .note {
            background: #fffbe6;
            border: 1px solid #ffe58f;
            border-left-width: 5px;
            padding: 15px;
            margin: 20px 0;
            border-radius: 5px;
        }
        .exam-tip strong {
            color: #d9534f;
        }
        .note strong {
            color: #0275d8;
        }
        .formula {
            background: #f4ecf7;
            border: 1px solid #d7bde2;
            padding: 15px;
            margin: 20px 0;
            font-family: "Courier New", Courier, monospace;
            font-size: 1.1em;
            overflow-x: auto;
        }
        #toc {
            background: #E8DAEF;
            border: 1px solid #8e44ad;
            padding: 15px 25px;
            border-radius: 5px;
            margin-bottom: 30px;
        }
        #toc h2 {
            margin-top: 0;
            border-bottom: none;
            color: #2c3e50;
        }
        #toc ul {
            list-style-type: none;
            padding-left: 0;
        }
        #toc ul li a {
            text-decoration: none;
            color: #7d3c98;
        }
        #toc ul li a:hover {
            text-decoration: underline;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Unit 4: Correlation and Regression</h1>

        <div id="toc">
            <h2>Table of Contents</h2>
            <ul>
                <li><a href="#bivariate">1. Bivariate Data and Scatter Diagram</a></li>
                <li><a href="#pearson">2. Karl Pearson's Coefficient of Correlation (r)</a></li>
                <li><a href="#spearman">3. Spearman's Rank Correlation Coefficient</a></li>
                <li><a href="#regression-lines">4. Regression: Lines of Regression</a></li>
                <li><a href="#regression-props">5. Properties of Regression Coefficients</a></li>
                <li><a href="#angle">6. Angle Between Two Regression Lines</a></li>
                <li><a href="#determination">7. Coefficient of Determination (r²)</a></li>
                <li><a href="#other-concepts">8. Other Correlation Concepts</a></li>
            </ul>
        </div>

        <section id="bivariate">
            <h2>1. Bivariate Data and Scatter Diagram</h2>
            
            <h3>Bivariate Data</h3>
            <p>Data that involves <strong>two different variables</strong>, where we are interested in the relationship between them. Each observation consists of a pair of values (x, y).</p>
            <ul>
                <li><em>Example:</em> Height (x) and Weight (y) of students.</li>
                <li><em>Example:</em> Advertising Expenditure (x) and Sales (y) of a product.</li>
            </ul>

            <h3>Scatter Diagram (or Scatter Plot)</h3>
            <p>The simplest way to visualize bivariate data. It's a graph where each (x, y) pair is plotted as a single point on a 2D plane.</p>
            <p>The pattern of the points helps us identify the <strong>type</strong> (linear, non-linear) and <strong>strength</strong> of the relationship.</p>
            <ul>
                <li><strong>Perfect Positive Correlation:</strong> Points form a perfect straight line sloping upwards.</li>
                <li><strong>High Positive Correlation:</strong> Points are tightly packed around a straight line sloping upwards.</li>
                <li><strong>Low Positive Correlation:</strong> Points are loosely scattered around a line sloping upwards.</li>
                <li><strong>Perfect Negative Correlation:</strong> Points form a perfect straight line sloping downwards.</li>
                <li><strong>High/Low Negative Correlation:</strong> Same as positive, but sloping downwards.</li>
                <li><strong>No Correlation (Zero Correlation):</strong> Points are randomly scattered with no clear pattern.</li>
            </ul>
        </section>

        <hr>

        <section id="pearson">
            <h2>2. Karl Pearson's Coefficient of Correlation (r)</h2>
            <p>Also known as the "product-moment correlation coefficient." It is a numerical measure of the <strong>strength and direction of the <em>linear</em> relationship</strong> between two quantitative variables.</p>
            
            <h3>Properties of 'r':</h3>
            <ul>
                <li><strong>Range:</strong> 'r' always lies between -1 and +1.
                    <ul>
                        <li><strong>r = +1:</strong> Perfect positive linear correlation.</li>
                        <li><strong>r = -1:</strong> Perfect negative linear correlation.</li>
                        <li><strong>r = 0:</strong> No <em>linear</em> correlation (there might still be a non-linear relationship).</li>
                    </ul>
                </li>
                <li><strong>Symmetrical:</strong> The correlation between x and y is the same as between y and x. (r<sub>xy</sub> = r<sub>yx</sub>).</li>
                <li><strong>Independent of Change of Origin and Scale:</strong> If you add/subtract a constant to x (change of origin) or multiply/divide x by a constant (change of scale), 'r' does not change. This is a very important property.</li>
            </ul>

            <h3>Formulas for 'r':</h3>
            
            <h4>1. Covariance Method</h4>
            <div class="formula">
                r = Cov(x, y) / (σ<sub>x</sub> * σ<sub>y</sub>)
                <br><br>
                Where:
                <br>
                - Cov(x, y) = ( Σ[(x - x̄)(y - ȳ)] ) / n   (Covariance of x and y)
                <br>
                - σ<sub>x</sub> = sqrt( (Σ(x - x̄)²) / n )   (Standard deviation of x)
                <br>
                - σ<sub>y</sub> = sqrt( (Σ(y - ȳ)²) / n )   (Standard deviation of y)
            </div>

            <h4>2. Raw Data (Computational) Formula</h4>
            <p>This is the most practical formula for calculations.</p>
            <div class="formula">
                r = [ n(Σxy) - (Σx)(Σy) ] / sqrt[ [n(Σx²) - (Σx)²] * [n(Σy²) - (Σy)²] ]
            </div>
            <div class="exam-tip">
                <strong>Exam Tip:</strong> To use this formula, create a table with 5 columns: x, y, x², y², xy. Then, find the sum (Σ) of each column and plug the values into the formula along with 'n' (the number of pairs).
            </div>
        </section>

        <hr>

        <section id="spearman">
            <h2>3. Spearman's Rank Correlation Coefficient (ρ or R)</h2>
            <p>This coefficient measures the strength and direction of the <strong>monotonic relationship</strong> between two variables. It is used when:</p>
            <ol>
                <li>The data is <strong>ordinal</strong> (ranked), like "best," "second best."</li>
                <li>The data is quantitative, but we suspect outliers or a non-linear (but still monotonic) relationship.</li>
            </ol>
            <p>It is essentially Pearson's 'r' calculated on the *ranks* of the data, not the values themselves.</p>

            <h3>Formula (when ranks are not tied):</h3>
            <div class="formula">
                R = 1 - [ ( 6 * Σd² ) / ( n * (n² - 1) ) ]
                <br><br>
                Where:
                <br>
                - <strong>d</strong> = Difference between the ranks of a pair: R<sub>x</sub> - R<sub>y</sub>
                <br>
                - <strong>n</strong> = Number of pairs of observations
            </div>

            <h3>Formula (when ranks are tied):</h3>
            <p>If two or more items have the same value, we assign them the <strong>average rank</strong>. (e.g., if 3 items are tied for 5th, they all get rank (5+6+7)/3 = 6).</p>
            <p>When ties occur, the formula must be corrected:</p>
            <div class="formula">
                R = 1 - [ ( 6 * (Σd² + CF) ) / ( n * (n² - 1) ) ]
                <br><br>
                Where CF is the <strong>Correction Factor</strong>:
                <br>
                CF = Σ [ m * (m² - 1) / 12 ]
                <br>
                - 'm' is the number of times an item is repeated (tied). You sum this for *all* tied groups in *both* x and y.
            </div>
            <div class="note">
                <strong>Example of CF:</strong> If in x, one value repeats 2 times (m=2) and in y, one value repeats 3 times (m=3):
                <br>
                CF = [ 2*(2²-1)/12 ] + [ 3*(3²-1)/12 ] = [ 2*3/12 ] + [ 3*8/12 ] = 0.5 + 2 = 2.5
            </div>
        </section>

        <hr>

        <section id="regression-lines">
            <h2>4. Regression: Lines of Regression</h2>
            <p>If correlation shows a relationship exists, regression describes that relationship with an equation. This equation can be used for <strong>prediction</strong>.</p>
            <p>A "line of regression" is the <strong>line of best fit</strong> for the data (found using the Principle of Least Squares from Unit 3). In bivariate analysis, there are <strong>two</strong> regression lines.</p>

            <h3>1. Regression Line of Y on X</h3>
            <p>This line is used to <strong>predict the value of Y, given a value of X</strong>.</p>
            <p><strong>Equation:</strong> (Y - ȳ) = b<sub>yx</sub> * (X - x̄)</p>
            <p>Here, <strong>b<sub>yx</sub></strong> is the <strong>regression coefficient of Y on X</strong> (the slope).</p>
            <div class="formula">
                b<sub>yx</sub> = Cov(x, y) / σ<sub>x</sub>²
                <br>
                b<sub>yx</sub> = r * (σ<sub>y</sub> / σ<sub>x</sub>)
                <br>
                b<sub>yx</sub> = [ n(Σxy) - (Σx)(Σy) ] / [ n(Σx²) - (Σx)² ]  <em>(Note: Denominator is same as in 'r', but without the sqrt)</em>
            </div>

            <h3>2. Regression Line of X on Y</h3>
            <p>This line is used to <strong>predict the value of X, given a value of Y</strong>.</p>
            <p><strong>Equation:</strong> (X - x̄) = b<sub>xy</sub> * (Y - ȳ)</p>
            <p>Here, <strong>b<sub>xy</sub></strong> is the <strong>regression coefficient of X on Y</strong>.</p>
            <div class="formula">
                b<sub>xy</sub> = Cov(x, y) / σ<sub>y</sub>²
                <br>
                b<sub>xy</sub> = r * (σ<sub>x</sub> / σ<sub>y</sub>)
                <br>
                b<sub>xy</sub> = [ n(Σxy) - (Σx)(Σy) ] / [ n(Σy²) - (Σy)² ]
            </div>

            <div class="note">
                <strong>Note:</strong> Both regression lines pass through the point (x̄, ȳ), which is the mean of x and the mean of y.
            </div>
        </section>

        <hr>

        <section id="regression-props">
            <h2>5. Properties of Regression Coefficients</h2>
            <p>These properties are extremely important for exam questions.</p>
            <ol>
                <li>
                    <strong>Geometric Mean:</strong> The correlation coefficient 'r' is the geometric mean of the two regression coefficients (b<sub>yx</sub> and b<sub>xy</sub>).
                    <div class="formula">r² = b<sub>yx</sub> * b<sub>xy</sub>   =>   r = ± sqrt(b<sub>yx</sub> * b<sub>xy</sub>)</div>
                </li>
                <li>
                    <strong>Sign:</strong> 'r', b<sub>yx</sub>, and b<sub>xy</sub> all have the <strong>same sign</strong>. If b<sub>yx</sub> is positive and b<sub>xy</sub> is positive, 'r' must be positive.
                </li>
                <li>
                    <strong>Magnitude:</strong> If one regression coefficient is greater than 1 (numerically), the other *must* be less than 1 (numerically). (Their product, r², cannot exceed 1).
                </li>
                <li>
                    <strong>Independence:</strong> Regression coefficients are *not* independent of change of scale, but they *are* independent of change of origin. (This is different from 'r'!).
                </li>
            </ol>
            <div class="exam-tip">
                <strong>Exam Tip:</strong> A classic question: "The two regression coefficients are 1.5 and 0.8. Find 'r'."
                <br>
                - Answer: r² = 1.5 * 0.8 = 1.2. This is <strong>impossible</strong>, as r² cannot be > 1. The data is inconsistent.
                <br>
                Another: "The two regression coefficients are -0.9 and -0.4. Find 'r'."
                <br>
                - Answer: r² = (-0.9) * (-0.4) = 0.36.
                <br>
                - r = ± sqrt(0.36) = ±0.6.
                <br>
                - Since both coefficients are negative, 'r' must also be negative.
                <br>
                - <strong>r = -0.6</strong>
            </div>
        </section>

        <hr>

        <section id="angle">
            <h2>6. Angle Between Two Regression Lines</h2>
            <p>The two regression lines (Y on X, X on Y) intersect at the point (x̄, ȳ). The angle (θ) between them gives an idea of the correlation strength.</p>
            <div class="formula">
                tan(θ) = [ (1 - r²) / (r) ] * [ (σ<sub>x</sub> * σ<sub>y</sub>) / (σ<sub>x</sub>² + σ<sub>y</sub>²) ]
                <br><br>
                <em>A simpler form using the slopes (m1 = b<sub>yx</sub>, m2 = 1/b<sub>xy</sub>):</em>
                <br>
                tan(θ) = | (m1 - m2) / (1 + m1 * m2) |
            </div>
            
            <h3>Key Insights:</h3>
            <ul>
                <li>If <strong>r = 0</strong>: tan(θ) = ∞ (infinity), so <strong>θ = 90°</strong>. The lines are perpendicular. This makes sense, as the variables are uncorrelated.</li>
                <li>If <strong>r = +1 or -1</strong>: tan(θ) = 0, so <strong>θ = 0°</strong>. The two lines are <strong>coincident</strong> (they become the same line). This means perfect correlation.</li>
                <li>The closer 'r' is to 0, the larger the angle. The closer 'r' is to ±1, the smaller the angle.</li>
            </ul>
        </section>

        <hr>

        <section id="determination">
            <h2>7. Coefficient of Determination (r²)</h2>
            <blockquote>
                <strong>Coefficient of Determination (r²):</strong> The square of the correlation coefficient (r). It represents the <strong>proportion of the total variance in the dependent variable (Y) that is explained or accounted for by the independent variable (X)</strong>.
            </blockquote>
            <ul>
                <li><strong>Range:</strong> 0 ≤ r² ≤ 1 (since it's a square).</li>
                <li><em>Example:</em> If r = 0.8, then r² = 0.64.</li>
                <li><strong>Interpretation:</strong> This means <strong>64%</strong> of the variation in Y can be explained by the linear relationship with X. The remaining 36% (1 - r²) is unexplained variation, due to other factors or random error.</li>
            </ul>
            <p><strong>Coefficient of Non-Determination (k²):</strong> This is the unexplained portion.
                <br>k² = 1 - r²
            </p>
        </section>

        <hr>

        <section id="other-concepts">
            <h2>8. Other Correlation Concepts</h2>
            
            <h3>Concept: Intra-class Correlation Coefficient</h3>
            <p>This coefficient measures the correlation *within* a class or group. It is used when you have data in groups (e.g., test scores of siblings in different families) and you want to see how similar items *within* the same group are, compared to items from different groups.</p>
            <p>It assesses the <strong>homogeneity</strong> within groups. A high intra-class correlation means items in the same group are very similar.</p>
            
            <h3>Concept: Correlation Ratio (η²)</h3>
            <p>Pearson's 'r' only measures <em>linear</em> relationships. What if the relationship is a strong curve (e.g., a U-shape)? Pearson's 'r' might be 0, which is misleading.</p>
            <p>The <strong>Correlation Ratio (η², "eta-squared")</strong> is a measure of association that can detect <strong>non-linear relationships</strong>. It is always positive (0 ≤ η² ≤ 1) and is related to the (unexplained) variance from a regression.</p>
            <ul>
                <li>If the relationship is perfectly linear, <strong>η² = r²</strong>.</li>
                <li>If the relationship is non-linear, <strong>η² > r²</strong>.</li>
                <li>It measures the proportion of variance in Y explained by X, regardless of whether the relationship is linear.</li>
            </ul>
        </section>

    </div>
  <script src="../../../../assets/scripts/units.js"></script>
</body>
</html>